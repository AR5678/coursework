---
title: "Predict Citibike"
author: "Alexandra Roffe (Yeshiva University)"
date: '6/16/2022'
---

```{r setup, include=FALSE}
library(scales)
library(tidyverse)
library(modelr)
library(broom)

theme_set(theme_bw())
options(repr.plot.width=4, repr.plot.height=3)
```

# Load in the Data Set
```{r}
trips_per_day = read_tsv('trips_per_day.tsv')
library(lubridate)
trips_per_day <- trips_per_day %>% 
  mutate(day_of_week = wday(ymd)) %>%
  mutate(weekday_or_weekend = as.integer(day_of_week > 1 & day_of_week < 7)) %>% # 1 and 7 are weekends. 
  mutate(prcp2 = as.integer(prcp > 0.7))


```

# Adding holidays
```{r}
holidays = read_csv('holidays.csv', c('row_number', 'ymd', 'title'))
trips_per_day <- left_join(trips_per_day, holidays, "ymd") %>%
  mutate(holiday = is.na(title)) %>%
  mutate(holiday1 = as.integer(holiday))
```

# Sample the data Set in 90% training and validation, 10% for testing

```{r}
set.seed(42)

num_days <- nrow(trips_per_day)
frac <- 0.9
num_train <- floor(num_day * frac)

#make a random sample
ndx <- sample(1:num_days, num_train, replace=F)

# used to fit the model
trips_per_day_train <- trips_per_day[ndx, ]

# used to evaluate the fit
trips_per_day_validate <- trips_per_day[-ndx, ]
```


# Model based on the minimum temperature for each day.  
Cross Validation:
  find the polynomial degree that generalizes best to held out data
```{r}

# fit a model for each polynomial degree
K <- 1:8
train_err <- c()
validate_err <- c()
for (k in K) {
  
    # fit on the training data
    model <- lm(num_trips ~ poly(tmin, k, raw = T), data=trips_per_day_train)
    
    # evaluate on the training data
    train_err[k] <- sqrt(mean((predict(model, trips_per_day_train) - trips_per_day_train$num_trips)^2))

    # evaluate on the validate data
    validate_err[k] <- sqrt(mean((predict(model, trips_per_day_validate) - trips_per_day_validate$num_trips)^2))
}

```



```{r}
plot_data <- data.frame(K, train_err, validate_err) %>%
  gather("split", "error", -K)

ggplot(plot_data, aes(x=K, y=error, color=split)) +
  geom_line() +
  scale_x_continuous(breaks=K) +
  xlab('Polynomial Degree') +
  ylab('RMSE')

```

# re-fiting the model and ploting the final results
```{r}

model <- lm(num_trips ~ poly(tmin, 4, raw = T), data = trips_per_day_train)

trips_per_day_train <- trips_per_day_train %>%
  add_predictions(model) %>%
  mutate(split = "train")
trips_per_day_validate <- trips_per_day_validate %>%
  add_predictions(model) %>%
  mutate(split = "validate")
plot_data <- bind_rows(trips_per_day_train, trips_per_day_validate)

ggplot(plot_data, aes(x = tmin, y = num_trips)) +
  geom_point(aes(color = split)) +
  geom_line(aes(y = pred)) +
  xlab('Minimum temperature') +
  ylab('Daily trips') +
  scale_y_continuous()
```



K-fold cross-validation:

```{r}
set.seed(42)
num_folds <- 10
num_days <- nrow(trips_per_day)

ndx <- sample(1:num_days, num_train, replace=F)

trips_per_day <- trips_per_day[ndx, ] %>%
  mutate(fold = (row_number() %% num_folds) + 1)
```

```{r}
K <- 1:8
avg_validate_err <- c()
se_validate_err <- c()
for (k in K) {

  # do 10-fold cross-validation within each value of k
  validate_err <- c()
  for (f in 1:num_folds) {
    # fit on the training data
    trips_per_day_train <- filter(trips_per_day, fold != f)
    model <- lm(num_trips ~ poly(tmin, k, raw = T), data=trips_per_day_train)

    # evaluate on the validation data
    trips_per_day_validate <- filter(trips_per_day, fold == f)
    validate_err[f] <- sqrt(mean((predict(model, trips_per_day_validate) - trips_per_day_validate$num_trips)^2))
  }

  # compute the average validation error across folds
  # and the standard error on this estimate
  avg_validate_err[k] <- mean(validate_err)
  se_validate_err[k] <- sd(validate_err) / sqrt(num_folds)
}

```


```{r}
# plot the validate error, highlighting the value of k with the lowest average error
plot_data <- data.frame(K, avg_validate_err, se_validate_err)
ggplot(plot_data, aes(x=K, y=avg_validate_err)) +
  geom_pointrange(aes(ymin=avg_validate_err - se_validate_err,
                      ymax=avg_validate_err + se_validate_err,
                      color=avg_validate_err == min(avg_validate_err))) +
  geom_line(color = "red") +
  scale_x_continuous(breaks=1:12) +
  theme(legend.position="none") +
  xlab('Polynomial Degree') +
  ylab('RMSE on validation data')

```


# Creative:
```{r}
# doing a linear transformation of the predictors tmax and tmin
lm.fit1 <- lm(num_trips ~ tmax*tmin, data=trips_per_day_train)
summary(lm.fit1)
```


```{r}
# doing a non-linear transformation of the predictors tmax and tmin
lm.fit2 <- lm(num_trips ~ I(tmax^4) + I(tmin^4), data=trips_per_day_train)
summary(lm.fit2)
```


# Compare models
  For anova the null hyposthsis is that the two models (lm.fit1, lm.fit2) are the same. The alternative is that they are different. Since the p-value is less than alpha, we can reject the null -- conclude that they are different. 
```{r}
anova(lm.fit1, lm.fit2)
```

```{r}
# doing a non-linear transformation of the predictors tmax and tmin
lm.fit3 <- lm(num_trips ~ I(tmin^4) + I(tmax^4)+ I(snwd^4) + I(snow^4), data=trips_per_day_train)
summary(lm.fit3)
tidy(lm.fit3)
glance(lm.fit3)
```
# Weekdays and weekends:

```{r}
lm.fit4 <- lm(num_trips ~ day_of_week, data=trips_per_day_train)
summary(lm.fit4)
```
```{r}
lm.fit5 <- lm(num_trips ~ I(day_of_week^4), data=trips_per_day_train)
summary(lm.fit5)
```


```{r}
lm.fit6 <- lm(num_trips ~ I(tmin^4) + I(tmax^4) + I(prcp^4) + I(snwd^4) + I(snow^4) + I(day_of_week^4), data=trips_per_day_train)
summary(lm.fit6)
```

# compare all things to 4 power with all things + day of week to 4th power
```{r}
# alpha = 0.05
anova(lm.fit3, lm.fit6)
# fail to reject null, there is no difference. 
```

We were wondering why day of the week did not have much correlation. We figured because it was using the features of sunday, monday, tuesday....saturday. We only wanted weekend vs weekday so we are trying this now:


```{r}
lm.fit7 <- lm(num_trips ~ weekday_or_weekend + I(weekday_or_weekend^4), data=trips_per_day_train)
summary(lm.fit7)
```


```{r}
lm.fit8 <- lm(num_trips ~ I(tmin^4) + I(tmax^4) + I(prcp^4) + I(snwd^4) + I(snow^4) + weekday_or_weekend, data=trips_per_day_train)
summary(lm.fit8)
par(mfrow = c(2, 2))
plot(lm.fit8)
```

```{r}
# this is comparing degrees - we will go with lm.fit7 to be better. 
lm.fit8 <- lm(num_trips ~ poly(tmin + tmax + prcp + snwd + snow, 4) + weekday_or_weekend, data=trips_per_day_train)
summary(lm.fit8)

```

```{r}
# this is comparing degrees - we will go with lm.fit7 to be better. 
#lm.fit9a <- lm(num_trips ~ poly(tmin, 4), data=trips_per_day_train)
#summary(lm.fit9a)
#lm.fit9b <- lm(num_trips ~ poly(tmax, 4), data=trips_per_day_train)
#summary(lm.fit9b)

lm.fit9c <- lm(num_trips ~ prcp * snwd, data=trips_per_day_train)
#summary(lm.fit9c)
tidy(lm.fit9c)
glance(lm.fit9c)

#lm.fit9d <- lm(num_trips ~ poly(snwd, 4), data=trips_per_day_train)
#summary(lm.fit9d)
#lm.fit9e <- lm(num_trips ~ poly(snow, 4), data=trips_per_day_train)
#summary(lm.fit9e)
```


```{r}

lm.fit10 <- lm(num_trips ~ I(tmin^3) + I(tmax^3) + weekday_or_weekend + I(prcp^1) + I(snwd^2) + I(snow^1) , data=trips_per_day_train)
#lm.fit10 <- lm(num_trips ~ I(tmin^4) + I(tmax^3) + I(snwd^2) + I(snow^1), data=trips_per_day_train)

summary(lm.fit10)
tidy(lm.fit10)
glance(lm.fit10)
```
```{r}
# 3890.724, 0.9257593, 0.8570302	
lm.fit11 <- lm(num_trips ~ I(tmax^2) + weekday_or_weekend + holiday1 + snow + sqrt(prcp) , data=trips_per_day_train)

summary(lm.fit11)
tidy(lm.fit11)
glance(lm.fit11)

```

```{r}
# 3831.79, 	0.9280797, 	0.861332	
lm.fit11a <- lm(num_trips ~ I(tmax^2) + weekday_or_weekend + holiday1 + day_of_week + sqrt(prcp) + snow, data=trips_per_day_train)

summary(lm.fit11a)
tidy(lm.fit11a)
glance(lm.fit11a)
```

```{r}
# 3828.257,  0.9282615,  0.8616695	
lm.fit11b <- lm(num_trips ~ I(tmax^2) + weekday_or_weekend + holiday1*day_of_week + sqrt(prcp) + snow, data=trips_per_day_train)

summary(lm.fit11b)
tidy(lm.fit11b)
glance(lm.fit11b)

# save:
save(lm.fit11b, file = "bestmodel.RData")
```
# Plotting:

```{r}
#lm.fit10()
model <- lm.fit11b

trips_per_day_train <- trips_per_day_train %>%
  add_predictions(model) %>%
  mutate(split = "train")
trips_per_day_validate <- trips_per_day_validate %>%
  add_predictions(model) %>%
  mutate(split = "validate")

plot_data <- bind_rows(trips_per_day_train, trips_per_day_validate)

ggplot(plot_data, aes(x = ymd, y = num_trips)) +
  geom_point(aes(color = factor(weekday_or_weekend))) +
  
  geom_line(aes(y = pred)) +
  #geom_smooth() +
  xlab('Date') +
  ylab('Daily trips') +
  scale_y_continuous()


```

# Second plot: actual vs Predicted
```{r}
options(repr.plot.width=4, repr.plot.height=3)

ggplot(plot_data, aes(x = pred, y = num_trips, color = factor(weekday_or_weekend))) +
  geom_point() +
  geom_abline(linetype = "dashed") +
  xlab('Predicted') +
  ylab('Actual')
```

```{r}
pred_actual <- plot_data %>%
  add_predictions(model) %>%
  mutate(actual = num_trips)

pred_actual %>%
  summarize(rmse = sqrt(mean((pred - actual)^2)),
            cor = cor(pred, actual),
            cor_sq = cor^2)
```




# Testing the last 10%




