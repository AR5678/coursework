<<<<<<< HEAD
---
title: "Movielens"
date: '`r Sys.time()`'
output:
  html_document:
    #code_folding: hide
    number_sections: yes
    toc: yes
    toc_depth: 3
---

```{r setup, include=FALSE}
library(scales)
library(tidyverse)
library(knitr)

# set plot theme
theme_set(theme_bw())
```

# Load and preview data

Read data from the `ratings.csv` file
```{r load-data}
ratings <- read_csv('ratings.csv',
                    col_names = c('user_id','movie_id','rating','timestamp'))
```

Loaded `r format(object.size(ratings), units="Mb")` of ratings data, containing `r format(nrow(ratings), big.mark = ",")` ratings. Here's a preview:
```{r preview-data}
head(ratings) %>% kable()
```

# Summary statistics

```{r dist-ratings}
# plot the distribution of rating values https://speakerdeck.com/jhofman/modeling-social-data-lecture-2-introduction-to-counting?slide=26

ratings %>%
  ggplot(aes(x = rating)) + 
  geom_histogram(bins = 10) 

```

## Per-movie stats

```{r aggregate-by-movie}
# aggregate ratings by movie, computing mean rating and number of ratings
# hint: use the n() function for easy counting within a group

# for each movie_id: average rating(0 to 5), number of ratings for that movie 
                    # average rating will be sum of rating / number of rating

mean_rating_movie <- ratings %>%
  group_by(movie_id) %>%
  mutate(sumOfRating = sum(rating), totalRatingCount = n(), mean_rating = sum(rating) / n())
  # get the average rating of each movie. 

```

```{r dist-movie-popularity}
# plot distribution of movie popularity (= number of ratings the movie received)
# hint: try scale_x_log10() for a logarithmic x axis

mean_rating_movie %>%
  ggplot(aes(x = totalRatingCount)) +
  geom_histogram(bins = 10) + scale_x_log10(label = comma)

```

```{r dist-mean-ratings-by-movie}
# plot distribution of mean ratings by movie https://speakerdeck.com/jhofman/modeling-social-data-lecture-2-introduction-to-counting?slide=28
# hint: try geom_histogram and geom_density


mean_rating_movie %>%
  ggplot(aes(x = mean_rating)) +
  geom_histogram(bins = 10) + scale_x_log10(label = comma)

mean_rating_movie %>%
  ggplot(aes(x = mean_rating)) + 
  geom_density(fill = "grey") + 
  scale_x_log10(label = comma)
  
```

```{r cdf-movie-pop}
# rank movies by popularity and compute the cdf, or fraction of movies covered by the top-k movies https://speakerdeck.com/jhofman/modeling-social-data-lecture-2-introduction-to-counting?slide=30
# hint: use dplyr's rank and arrange functions, and the base R sum and cumsum functions
# store the result in a new data frame so you can use it in creating figure 2 from the paper below


# plot the CDF of movie popularity
f1 <- mean_rating_movie %>%
  arrange(desc(totalRatingCount)) %>%
  mutate(poprank = row_number(), sum = cumsum(totalRatingCount)/sum(totalRatingCount))

# f1 is the movie, number of ratings, total amount of ratings in total. 

f1 %>%
  ggplot(aes(x = poprank, y = sum)) + 
  geom_line()

```


# Per-user stats

```{r aggregate-by-user}
# aggregate ratings by user, computing mean and number of ratings

# person's id, average rating (sum of all the ratings), how many ratings they gave. 

user_rating <- ratings %>%
  group_by(user_id) %>%
  summarize(movie_id, sumOfRating = sum(rating), totalRatingCount = n(), mean_rating = sum(rating) / n())

```

```{r dist-user-activity}
# plot distribution of user activity (= number of ratings the user made)
# hint: try a log scale here

user_rating %>%
  ggplot(aes(x = totalRatingCount)) +
  geom_histogram(bins = 10) + scale_x_log10(label = comma)

```

# Anatomy of the long tail

```{r long-tail}
# generate the equivalent of figure 2 of this paper:
# https://5harad.com/papers/long_tail.pdf

# Specifically, for the subset of users who rated at least 10 movies,
# produce a plot that shows the fraction of users satisfied (vertical
# axis) as a function of inventory size (horizontal axis). We will
# define "satisfied" as follows: an individual user is satisfied p% of
# the time at inventory of size k if at least p% of the movies they
# rated are contained in the top k most popular movies. As in the
# paper, produce one curve for the 100% user satisfaction level and
# another for 90%---do not, however, bother implementing the null
# model (shown in the dashed lines).

# user_id, movie_id, pop_rank. 
user_rank <- inner_join(user_rating, f1, "movie_id")


user_sat <- user_rank %>% 
  summarize(sat_100 = max(poprank), sat_90 = quantile(poprank, probs = 0.9))

# user_id, poprank (weirdest movie rank), 

user100 <- user_sat %>%
  group_by(sat_100) %>%
  summarize(num_sat = n()) %>%
  ungroup() %>%
  arrange(user100, sat_100) %>%
  mutate(frac_users_sat = cumsum(num_sat) / sum(num_sat))

user90 <- user_sat %>%
  group_by(sat_90) %>%
  summarize(num_sat = n()) %>%
  ungroup() %>%
  arrange(sat_90) %>%
  mutate(frac_users_sat = cumsum(num_sat) / sum(num_sat))

ggplot() + 
  geom_line(user100, mapping = aes(x = sat_100, y = frac_users_sat)) + 
  geom_line(user90, mapping = aes(x = sat_90, y = frac_users_sat)) +
  xlab("Inventory Size") + 
  ylab("Percent of Users Satisfied")



```


=======
---
title: "Movielens"
date: '`r Sys.time()`'
output:
  html_document:
    #code_folding: hide
    number_sections: yes
    toc: yes
    toc_depth: 3
---

```{r setup, include=FALSE}
library(scales)
library(tidyverse)
library(knitr)

# set plot theme
theme_set(theme_bw())
```

# Load and preview data

Read data from the `ratings.csv` file
```{r load-data}
ratings <- read_csv('ratings.csv',
                    col_names = c('user_id','movie_id','rating','timestamp'))
```

Loaded `r format(object.size(ratings), units="Mb")` of ratings data, containing `r format(nrow(ratings), big.mark = ",")` ratings. Here's a preview:
```{r preview-data}
head(ratings) %>% kable()
```

# Summary statistics

```{r dist-ratings}
# plot the distribution of rating values https://speakerdeck.com/jhofman/modeling-social-data-lecture-2-introduction-to-counting?slide=26
```

## Per-movie stats

```{r aggregate-by-movie}
# aggregate ratings by movie, computing mean rating and number of ratings
# hint: use the n() function for easy counting within a group
```

```{r dist-movie-popularity}
# plot distribution of movie popularity (= number of ratings the movie received)
# hint: try scale_x_log10() for a logarithmic x axis
```

```{r dist-mean-ratings-by-movie}
# plot distribution of mean ratings by movie https://speakerdeck.com/jhofman/modeling-social-data-lecture-2-introduction-to-counting?slide=28
# hint: try geom_histogram and geom_density
```

```{r cdf-movie-pop}
# rank movies by popularity (number of ratings) and compute the cdf, or fraction of movies covered by the top-k movies https://speakerdeck.com/jhofman/modeling-social-data-lecture-2-introduction-to-counting?slide=30
# hint: use dplyr's rank and arrange functions, and the base R sum and cumsum functions
# store the result in a new data frame so you can use it in creating figure 2 from the paper below

# plot the CDF of movie popularity
```


# Per-user stats

```{r aggregate-by-user}
# aggregate ratings by user, computing mean and number of ratings
```

```{r dist-user-activity}
# plot distribution of user activity (= number of ratings the user made)
# hint: try a log scale here
```

# Anatomy of the long tail

```{r long-tail}
# generate the equivalent of figure 2a of this paper:
# note: don't worry about the "null model" lines
# just do the solid lines and dotted line (optional)
# https://5harad.com/papers/long_tail.pdf

# Specifically, for the subset of users who rated at least 10 movies,
# produce a plot that shows the fraction of users satisfied (vertical
# axis) as a function of inventory size (horizontal axis). We will
# define "satisfied" as follows: an individual user is satisfied p% of
# the time at inventory of size k if at least p% of the movies they
# rated are contained in the top k most popular movies. As in the
# paper, produce one curve for the 100% user satisfaction level and
# another for 90%---do not, however, bother implementing the null
# model (shown in the dashed lines).
```
>>>>>>> 13b8b7263944211c6971d99d8bc94ba7722f7e8d
